{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf8a60b-bd71-477e-8f9a-0b63085c3f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Munna Bhaiyya\n"
     ]
    }
   ],
   "source": [
    "print ('Missing Munna Bhaiyya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc758369-2728-496d-a1a8-65f96f0c4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4865867-680e-4d86-839d-ff4ffd2c6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c6fb2b-14e8-48eb-9307-0a6df3063579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a 27*27 array as this is a bigram modeal\n",
    "N = torch.zeros((27,27), dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28673d66-ba33-4ca7-b7b6-c8e2215990bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "#stoi['<E>'] = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9821c1-11ac-4ddb-9e28-17adec977200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1,ix2] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51535904-15c9-4893-8ecb-8c91962e14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcfc643-760a-474a-b2a3-ecc672b61f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = P[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6443c5-6c9e-4b99-b488-dfbb57a39907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_nll=tensor(2.4544)\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation using log likelyhood\n",
    "#1 Print bigrams of first 3 words in the dataset\n",
    "#3 find prob of those bigrams in the trained model\n",
    "#find logprob and negative logprob, eventually to define a loss function that we try to minimize by manupilating the weights\n",
    "\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for w in words:\n",
    "#for w in [\"srikar\"]:\n",
    "    chs = ['.']+list(w)+['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        log_prob = torch.log(prob)\n",
    "        log_likelihood += log_prob\n",
    "        n +=1\n",
    "        #print(f'{ch1}{ch2}:{log_prob:.4f}:{log_likelihood=}')\n",
    "nll = - log_likelihood\n",
    "avg_nll = nll/n\n",
    "print(f'{avg_nll=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98461aaa-1010-4abc-980a-9048d4b07816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving into Neural net approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09630e89-6a1c-4089-8146-fc3482a3ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training set for the neural net\n",
    "#generate tuples from the word list. Get the corresponding integer for a given letter from strinToInt stoic matrix\n",
    "#store them in xs and ys arrays\n",
    "\n",
    "xs, ys = [], []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7948ccfe-5aa7-4a96-849a-c1ed23fae837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Pass\n",
    "#Use one-hot encoding to convert the xs into a float type matrix\n",
    "\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()#\n",
    "\n",
    "#Randomise weights for the inputs neurons\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(27,27, generator=g, requires_grad = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81978890-fb3c-467a-88da-19ba154f55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(18.8465, grad_fn=<NegBackward0>)\n",
      "loss=tensor(1.5580, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    #Forward pass\n",
    "    logits = xenc @ W #these are log of count of N matrix\n",
    "    counts = logits.exp() #Taking exponential function will give us the actual counts\n",
    "    probs = counts/counts.sum(1, keepdims = True) #normalize the counts to get the probability\n",
    "    \n",
    "    #Last two steps are called softmax. It takes any integers tensor as input and gives a probabilites as output\n",
    "    \n",
    "    #Get loss function\n",
    "    #We use logloss as this is a classifaction type problem\n",
    "    \n",
    "    #1 get the probabilites of ys in the current model\n",
    "    yhat = probs[torch.arange(5),ys]\n",
    "    #2 get log of yhat\n",
    "    yhatlog = yhat.log()\n",
    "    #3 loss is the sum of negative log likelihood\n",
    "    loss = -yhatlog.sum()\n",
    "    print(f'{loss=}')\n",
    "    \n",
    "    #backwardpass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    #upgrade the Weigth by slightly nudging the wieghts by 0.1\n",
    "    W.data = -8*W.grad  #-0.1 beacuse we want to decrease the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a52ba363-d746-4e5f-864c-e55100e67e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x']\n",
      "['x', 't']\n",
      "['x', 't', 'w']\n",
      "['x', 't', 'w', 'm']\n",
      "['x', 't', 'w', 'm', 'x']\n",
      "['x', 't', 'w', 'm', 'x', 'c']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n', 'l']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n', 'l', 'w']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n', 'l', 'w', 'w']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n', 'l', 'w', 'w', 'k']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n', 'l', 'w', 'w', 'k', 'y']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n', 'l', 'w', 'w', 'k', 'y', '.']\n",
      "['x', 't', 'w', 'm', 'x', 'c', 'n', 'r', 'x', 'i', 'd', 'x', 'm', 'x', 'l', 'n', 'l', 'w', 'w', 'k', 'y', '.']\n"
     ]
    }
   ],
   "source": [
    "#drawing letters from the bi-gram neural net model\n",
    "out = [];\n",
    "ix = 0;\n",
    "while True:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes = 27).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts/counts.sum(1, keepdims = True)\n",
    "    ix = torch.multinomial(probs, num_samples = 1, replacement = True).item()\n",
    "    out.append(itos[ix])\n",
    "    print(out)\n",
    "    if ix == 0:\n",
    "        break\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef84a9-ad9d-4603-bb7d-338acaf62e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backwardpass\n",
    "W.grad = None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "20f661a8-6c75-4db9-90b3-a4565f1058ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d967598-7243-4de6-8dce-946910b24e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddce59f-2d27-47e4-97ab-9e70c68de53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3ff82-0ac9-46d7-9147-0cc28a9d74d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
